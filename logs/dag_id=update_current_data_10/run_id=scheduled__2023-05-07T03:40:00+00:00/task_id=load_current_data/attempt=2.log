[2023-07-05T10:34:08.405+0100] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: update_current_data_10.load_current_data scheduled__2023-05-07T03:40:00+00:00 [queued]>
[2023-07-05T10:34:08.413+0100] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: update_current_data_10.load_current_data scheduled__2023-05-07T03:40:00+00:00 [queued]>
[2023-07-05T10:34:08.413+0100] {taskinstance.py:1308} INFO - Starting attempt 2 of 3
[2023-07-05T10:34:08.423+0100] {taskinstance.py:1327} INFO - Executing <Task(PythonOperator): load_current_data> on 2023-05-07 03:40:00+00:00
[2023-07-05T10:34:08.427+0100] {standard_task_runner.py:57} INFO - Started process 44993 to run task
[2023-07-05T10:34:08.431+0100] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'update_current_data_10', 'load_current_data', 'scheduled__2023-05-07T03:40:00+00:00', '--job-id', '289', '--raw', '--subdir', '/home/haboubi/Desktop/api/API_weather/dags/update_current_dags.py', '--cfg-path', '/tmp/tmpmchpl2f5']
[2023-07-05T10:34:08.432+0100] {standard_task_runner.py:85} INFO - Job 289: Subtask load_current_data
[2023-07-05T10:34:08.495+0100] {task_command.py:410} INFO - Running <TaskInstance: update_current_data_10.load_current_data scheduled__2023-05-07T03:40:00+00:00 [running]> on host haboubi-VivoBook-15-ASUS-Laptop-X540UB
[2023-07-05T10:34:08.587+0100] {taskinstance.py:1545} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='haboubi' AIRFLOW_CTX_DAG_ID='update_current_data_10' AIRFLOW_CTX_TASK_ID='load_current_data' AIRFLOW_CTX_EXECUTION_DATE='2023-05-07T03:40:00+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-05-07T03:40:00+00:00'
[2023-07-05T10:34:08.604+0100] {logging_mixin.py:149} INFO - ['Paris', datetime.date(2023, 7, 4)]
[2023-07-05T10:34:08.619+0100] {taskinstance.py:1824} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/airflow/operators/python.py", line 181, in execute
    return_value = self.execute_callable()
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/airflow/operators/python.py", line 198, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/home/haboubi/Desktop/api/API_weather/dags/update_current_dags.py", line 52, in load_updated_data_db
    loc=session.query().filter(Location.name == i[0]).first()
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2824, in first
    return self.limit(1)._iter().first()
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1569, in _execute_clauseelement
    compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 532, in _compile_w_cache
    compiled_sql = self._compiler(
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 567, in _compiler
    return dialect.statement_compiler(dialect, self, **kw)
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/sql/compiler.py", line 809, in __init__
    Compiled.__init__(self, dialect, statement, **kwargs)
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/sql/compiler.py", line 464, in __init__
    self.string = self.process(self.statement, **compile_kwargs)
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/sql/compiler.py", line 499, in process
    return obj._compiler_dispatch(self, **kwargs)
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/sql/visitors.py", line 82, in _compiler_dispatch
    return meth(self, **kw)
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/sql/compiler.py", line 3405, in visit_select
    compile_state = select_stmt._compile_state_factory(
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/sql/base.py", line 510, in create_for_statement
    return klass.create_for_statement(statement, compiler, **kw)
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/orm/context.py", line 765, in create_for_statement
    self._setup_for_generate()
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/orm/context.py", line 895, in _setup_for_generate
    raise sa_exc.InvalidRequestError(
sqlalchemy.exc.InvalidRequestError: Query contains no columns with which to SELECT from.
[2023-07-05T10:34:08.636+0100] {taskinstance.py:1345} INFO - Marking task as UP_FOR_RETRY. dag_id=update_current_data_10, task_id=load_current_data, execution_date=20230507T034000, start_date=20230705T093408, end_date=20230705T093408
[2023-07-05T10:34:08.646+0100] {standard_task_runner.py:104} ERROR - Failed to execute job 289 for task load_current_data (Query contains no columns with which to SELECT from.; 44993)
[2023-07-05T10:34:08.682+0100] {local_task_job_runner.py:225} INFO - Task exited with return code 1
[2023-07-05T10:34:08.711+0100] {taskinstance.py:2653} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-07-05T10:54:52.461+0100] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: update_current_data_10.load_current_data scheduled__2023-05-07T03:40:00+00:00 [queued]>
[2023-07-05T10:54:52.471+0100] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: update_current_data_10.load_current_data scheduled__2023-05-07T03:40:00+00:00 [queued]>
[2023-07-05T10:54:52.472+0100] {taskinstance.py:1308} INFO - Starting attempt 2 of 3
[2023-07-05T10:54:52.487+0100] {taskinstance.py:1327} INFO - Executing <Task(PythonOperator): load_current_data> on 2023-05-07 03:40:00+00:00
[2023-07-05T10:54:52.493+0100] {standard_task_runner.py:57} INFO - Started process 62888 to run task
[2023-07-05T10:54:52.497+0100] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'update_current_data_10', 'load_current_data', 'scheduled__2023-05-07T03:40:00+00:00', '--job-id', '607', '--raw', '--subdir', '/home/haboubi/Desktop/api/API_weather/dags/update_current_dags.py', '--cfg-path', '/tmp/tmppvetui5n']
[2023-07-05T10:54:52.498+0100] {standard_task_runner.py:85} INFO - Job 607: Subtask load_current_data
[2023-07-05T10:54:52.571+0100] {task_command.py:410} INFO - Running <TaskInstance: update_current_data_10.load_current_data scheduled__2023-05-07T03:40:00+00:00 [running]> on host haboubi-VivoBook-15-ASUS-Laptop-X540UB
[2023-07-05T10:54:52.667+0100] {taskinstance.py:1545} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='haboubi' AIRFLOW_CTX_DAG_ID='update_current_data_10' AIRFLOW_CTX_TASK_ID='load_current_data' AIRFLOW_CTX_EXECUTION_DATE='2023-05-07T03:40:00+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-05-07T03:40:00+00:00'
[2023-07-05T10:54:52.685+0100] {logging_mixin.py:149} INFO - ['Paris', datetime.date(2023, 7, 4)]
[2023-07-05T10:54:52.705+0100] {taskinstance.py:1824} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1905, in _execute_context
    self.dialect.do_execute(
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "locations" does not exist
LINE 2: FROM locations 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/airflow/operators/python.py", line 181, in execute
    return_value = self.execute_callable()
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/airflow/operators/python.py", line 198, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/home/haboubi/Desktop/api/API_weather/dags/update_current_dags.py", line 52, in load_updated_data_db
    loc=session.query(Location).filter(Location.name == i[0]).first()
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2824, in first
    return self.limit(1)._iter().first()
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1948, in _execute_context
    self._handle_dbapi_exception(
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    util.raise_(
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1905, in _execute_context
    self.dialect.do_execute(
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "locations" does not exist
LINE 2: FROM locations 
             ^

[SQL: SELECT locations.id AS locations_id, locations.name AS locations_name, locations.country AS locations_country, locations.lat AS locations_lat, locations.lon AS locations_lon, locations.last_update_day AS locations_last_update_day 
FROM locations 
WHERE locations.name = %(name_1)s 
 LIMIT %(param_1)s]
[parameters: {'name_1': 'Paris', 'param_1': 1}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2023-07-05T10:54:52.722+0100] {taskinstance.py:1345} INFO - Marking task as UP_FOR_RETRY. dag_id=update_current_data_10, task_id=load_current_data, execution_date=20230507T034000, start_date=20230705T095452, end_date=20230705T095452
[2023-07-05T10:54:52.732+0100] {standard_task_runner.py:104} ERROR - Failed to execute job 607 for task load_current_data ((psycopg2.errors.UndefinedTable) relation "locations" does not exist
LINE 2: FROM locations 
             ^

[SQL: SELECT locations.id AS locations_id, locations.name AS locations_name, locations.country AS locations_country, locations.lat AS locations_lat, locations.lon AS locations_lon, locations.last_update_day AS locations_last_update_day 
FROM locations 
WHERE locations.name = %(name_1)s 
 LIMIT %(param_1)s]
[parameters: {'name_1': 'Paris', 'param_1': 1}]
(Background on this error at: https://sqlalche.me/e/14/f405); 62888)
[2023-07-05T10:54:52.748+0100] {local_task_job_runner.py:225} INFO - Task exited with return code 1
[2023-07-05T10:54:52.777+0100] {taskinstance.py:2653} INFO - 0 downstream tasks scheduled from follow-on schedule check
