[2023-07-05T10:33:37.382+0100] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: update_current_data_10.load_current_data scheduled__2023-05-07T01:40:00+00:00 [queued]>
[2023-07-05T10:33:37.394+0100] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: update_current_data_10.load_current_data scheduled__2023-05-07T01:40:00+00:00 [queued]>
[2023-07-05T10:33:37.394+0100] {taskinstance.py:1308} INFO - Starting attempt 3 of 3
[2023-07-05T10:33:37.405+0100] {taskinstance.py:1327} INFO - Executing <Task(PythonOperator): load_current_data> on 2023-05-07 01:40:00+00:00
[2023-07-05T10:33:37.412+0100] {standard_task_runner.py:57} INFO - Started process 44496 to run task
[2023-07-05T10:33:37.416+0100] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'update_current_data_10', 'load_current_data', 'scheduled__2023-05-07T01:40:00+00:00', '--job-id', '280', '--raw', '--subdir', '/home/haboubi/Desktop/api/API_weather/dags/update_current_dags.py', '--cfg-path', '/tmp/tmp1t_c7b8c']
[2023-07-05T10:33:37.417+0100] {standard_task_runner.py:85} INFO - Job 280: Subtask load_current_data
[2023-07-05T10:33:37.497+0100] {task_command.py:410} INFO - Running <TaskInstance: update_current_data_10.load_current_data scheduled__2023-05-07T01:40:00+00:00 [running]> on host haboubi-VivoBook-15-ASUS-Laptop-X540UB
[2023-07-05T10:33:37.600+0100] {taskinstance.py:1545} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='haboubi' AIRFLOW_CTX_DAG_ID='update_current_data_10' AIRFLOW_CTX_TASK_ID='load_current_data' AIRFLOW_CTX_EXECUTION_DATE='2023-05-07T01:40:00+00:00' AIRFLOW_CTX_TRY_NUMBER='3' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-05-07T01:40:00+00:00'
[2023-07-05T10:33:37.626+0100] {logging_mixin.py:149} INFO - ['Paris', datetime.date(2023, 7, 4)]
[2023-07-05T10:33:37.641+0100] {taskinstance.py:1824} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/airflow/operators/python.py", line 181, in execute
    return_value = self.execute_callable()
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/airflow/operators/python.py", line 198, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/home/haboubi/Desktop/api/API_weather/dags/update_current_dags.py", line 52, in load_updated_data_db
    loc=session.query().filter(Location.name == i[0]).first()
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2824, in first
    return self.limit(1)._iter().first()
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1569, in _execute_clauseelement
    compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 532, in _compile_w_cache
    compiled_sql = self._compiler(
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 567, in _compiler
    return dialect.statement_compiler(dialect, self, **kw)
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/sql/compiler.py", line 809, in __init__
    Compiled.__init__(self, dialect, statement, **kwargs)
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/sql/compiler.py", line 464, in __init__
    self.string = self.process(self.statement, **compile_kwargs)
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/sql/compiler.py", line 499, in process
    return obj._compiler_dispatch(self, **kwargs)
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/sql/visitors.py", line 82, in _compiler_dispatch
    return meth(self, **kw)
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/sql/compiler.py", line 3405, in visit_select
    compile_state = select_stmt._compile_state_factory(
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/sql/base.py", line 510, in create_for_statement
    return klass.create_for_statement(statement, compiler, **kw)
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/orm/context.py", line 765, in create_for_statement
    self._setup_for_generate()
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/orm/context.py", line 895, in _setup_for_generate
    raise sa_exc.InvalidRequestError(
sqlalchemy.exc.InvalidRequestError: Query contains no columns with which to SELECT from.
[2023-07-05T10:33:37.661+0100] {taskinstance.py:1345} INFO - Marking task as FAILED. dag_id=update_current_data_10, task_id=load_current_data, execution_date=20230507T014000, start_date=20230705T093337, end_date=20230705T093337
[2023-07-05T10:33:37.671+0100] {standard_task_runner.py:104} ERROR - Failed to execute job 280 for task load_current_data (Query contains no columns with which to SELECT from.; 44496)
[2023-07-05T10:33:37.708+0100] {local_task_job_runner.py:225} INFO - Task exited with return code 1
[2023-07-05T10:33:37.760+0100] {taskinstance.py:2653} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-07-05T10:54:43.072+0100] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: update_current_data_10.load_current_data scheduled__2023-05-07T01:40:00+00:00 [queued]>
[2023-07-05T10:54:43.091+0100] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: update_current_data_10.load_current_data scheduled__2023-05-07T01:40:00+00:00 [queued]>
[2023-07-05T10:54:43.092+0100] {taskinstance.py:1308} INFO - Starting attempt 3 of 3
[2023-07-05T10:54:43.116+0100] {taskinstance.py:1327} INFO - Executing <Task(PythonOperator): load_current_data> on 2023-05-07 01:40:00+00:00
[2023-07-05T10:54:43.121+0100] {standard_task_runner.py:57} INFO - Started process 62702 to run task
[2023-07-05T10:54:43.125+0100] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'update_current_data_10', 'load_current_data', 'scheduled__2023-05-07T01:40:00+00:00', '--job-id', '604', '--raw', '--subdir', '/home/haboubi/Desktop/api/API_weather/dags/update_current_dags.py', '--cfg-path', '/tmp/tmpvc3oi7l9']
[2023-07-05T10:54:43.128+0100] {standard_task_runner.py:85} INFO - Job 604: Subtask load_current_data
[2023-07-05T10:54:43.216+0100] {task_command.py:410} INFO - Running <TaskInstance: update_current_data_10.load_current_data scheduled__2023-05-07T01:40:00+00:00 [running]> on host haboubi-VivoBook-15-ASUS-Laptop-X540UB
[2023-07-05T10:54:43.333+0100] {taskinstance.py:1545} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='haboubi' AIRFLOW_CTX_DAG_ID='update_current_data_10' AIRFLOW_CTX_TASK_ID='load_current_data' AIRFLOW_CTX_EXECUTION_DATE='2023-05-07T01:40:00+00:00' AIRFLOW_CTX_TRY_NUMBER='3' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-05-07T01:40:00+00:00'
[2023-07-05T10:54:43.356+0100] {logging_mixin.py:149} INFO - ['Paris', datetime.date(2023, 7, 4)]
[2023-07-05T10:54:43.381+0100] {taskinstance.py:1824} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1905, in _execute_context
    self.dialect.do_execute(
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "locations" does not exist
LINE 2: FROM locations 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/airflow/operators/python.py", line 181, in execute
    return_value = self.execute_callable()
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/airflow/operators/python.py", line 198, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/home/haboubi/Desktop/api/API_weather/dags/update_current_dags.py", line 52, in load_updated_data_db
    loc=session.query(Location).filter(Location.name == i[0]).first()
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2824, in first
    return self.limit(1)._iter().first()
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1948, in _execute_context
    self._handle_dbapi_exception(
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2129, in _handle_dbapi_exception
    util.raise_(
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1905, in _execute_context
    self.dialect.do_execute(
  File "/home/haboubi/Desktop/api/API_weather/api_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "locations" does not exist
LINE 2: FROM locations 
             ^

[SQL: SELECT locations.id AS locations_id, locations.name AS locations_name, locations.country AS locations_country, locations.lat AS locations_lat, locations.lon AS locations_lon, locations.last_update_day AS locations_last_update_day 
FROM locations 
WHERE locations.name = %(name_1)s 
 LIMIT %(param_1)s]
[parameters: {'name_1': 'Paris', 'param_1': 1}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2023-07-05T10:54:43.400+0100] {taskinstance.py:1345} INFO - Marking task as FAILED. dag_id=update_current_data_10, task_id=load_current_data, execution_date=20230507T014000, start_date=20230705T095443, end_date=20230705T095443
[2023-07-05T10:54:43.413+0100] {standard_task_runner.py:104} ERROR - Failed to execute job 604 for task load_current_data ((psycopg2.errors.UndefinedTable) relation "locations" does not exist
LINE 2: FROM locations 
             ^

[SQL: SELECT locations.id AS locations_id, locations.name AS locations_name, locations.country AS locations_country, locations.lat AS locations_lat, locations.lon AS locations_lon, locations.last_update_day AS locations_last_update_day 
FROM locations 
WHERE locations.name = %(name_1)s 
 LIMIT %(param_1)s]
[parameters: {'name_1': 'Paris', 'param_1': 1}]
(Background on this error at: https://sqlalche.me/e/14/f405); 62702)
[2023-07-05T10:54:43.459+0100] {local_task_job_runner.py:225} INFO - Task exited with return code 1
[2023-07-05T10:54:43.490+0100] {taskinstance.py:2653} INFO - 0 downstream tasks scheduled from follow-on schedule check
